# -*- coding: utf-8 -*-
"""signverifcation2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lJnjf4Kj9Z8st0TJmN-G7NIrgvC8iox7
"""

import os
import cv2
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Define paths
base_dir = "signature"
train_dir = os.path.join(base_dir, "train")
test_dir = os.path.join(base_dir, "test")
genuine_dir = os.path.join(train_dir, "genuine")
forged_dir = os.path.join(train_dir, "forged")

# Create directories if they don't exist
os.makedirs(genuine_dir, exist_ok=True)
os.makedirs(forged_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)


# Dataset creation and augmentation
def augment_and_save(image_path, label, num_augmented=100):
    img = cv2.imread(image_path)
    if img is None:
        print(f"Error: Unable to read image at {image_path}.")
        return
    datagen = ImageDataGenerator(
        rotation_range=30,
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=False,
        fill_mode='nearest'
    )
    img = img.reshape((1,) + img.shape)
    for i, batch in enumerate(datagen.flow(img, batch_size=1)):
        augmented_img = batch[0].astype(np.uint8)
        aug_img_name = os.path.join(label, f"{label.split('/')[-1]}_{i}.png")
        cv2.imwrite(aug_img_name, augmented_img)
        if i >= num_augmented - 1:
            break

def create_signature_dataset():
    genuine_signature_path = input("Enter the path for the genuine signature image: ")
    forged_signature_path = input("Enter the path for the forged signature image: ")

    # Augment the images
    augment_and_save(genuine_signature_path, genuine_dir)
    augment_and_save(forged_signature_path, forged_dir)

    # Save the original images in the test directory
    cv2.imwrite(os.path.join(test_dir, "test_genuine.png"), cv2.imread(genuine_signature_path))
    cv2.imwrite(os.path.join(test_dir, "test_forged.png"), cv2.imread(forged_signature_path))

# Load dataset and preprocess images
def load_dataset():
    images, labels = [], []
    for label, directory in zip([0, 1], [genuine_dir, forged_dir]):
        for img_name in os.listdir(directory):
            img_path = os.path.join(directory, img_name)
            img = cv2.imread(img_path)
            if img is None:
                continue
            img = cv2.resize(img, (100, 100))  # Resize to match model input size
            images.append(img)
            labels.append(label)
    return np.array(images), np.array(labels)

# Build the model using a simple CNN
def build_model():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),
        MaxPooling2D(pool_size=(2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dense(1, activation='sigmoid')  # Binary classification (0 or 1)
    ])
    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Build the model using VGG16 (pre-trained model)
def build_pretrained_model():
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))
    for layer in base_model.layers:
        layer.trainable = False
    model = Sequential([
        base_model,
        Flatten(),
        Dense(128, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Train and evaluate the model
def train_and_evaluate(model, X_train, X_val, y_train, y_val, X_test, y_test):
    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

    # Plot training and validation accuracy
    plt.plot(history.history['accuracy'], label='train accuracy')
    plt.plot(history.history['val_accuracy'], label='validation accuracy')
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend()
    plt.show()

    # Evaluate on test set
    test_loss, test_accuracy = model.evaluate(X_test, y_test)
    print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Verify a signature using the trained model
def verify_signature(model, signature_path):
    img = cv2.imread(signature_path)
    img = cv2.resize(img, (100, 100))
    img = img.reshape((1, 100, 100, 3)).astype('float32') / 255.0  # Normalize
    prediction = model.predict(img)
    return "Genuine" if prediction[0][0] < 0.5 else "Forged"

# Main function to tie everything together
def main():
    # Step 1: Create the signature dataset
    create_signature_dataset()

    # Step 2: Load the dataset
    images, labels = load_dataset()
    images = images.astype('float32') / 255.0  # Normalize images

    # Step 3: Split data into training, validation, and test sets
    X_train, X_rem, y_train, y_rem = train_test_split(images, labels, test_size=0.2, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42)

    # Step 4: Build and train the model
    model = build_pretrained_model()  # Or use `build_model()` for a simple CNN
    train_and_evaluate(model, X_train, X_val, y_train, y_val, X_test, y_test)

    # Step 5: Verify a signature
    test_signature_path = input("Enter the path for the signature to verify: ")
    result = verify_signature(model, test_signature_path)
    print(f"The signature is: {result}")

if __name__ == "__main__":
    main()